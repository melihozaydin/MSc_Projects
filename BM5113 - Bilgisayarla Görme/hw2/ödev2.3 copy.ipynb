{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-) \n",
    "\n",
    "* Edinburgh mutfak eşyaları veri seti1 için hazırlanan ekteki 10 farklı nesneye ait görüntüler \n",
    "ile bir nesne sınıflandırma sistemi gerçekleştiriniz. \n",
    "\n",
    "* Bunun için nesnelerin RAW olarak isimlendirilmiş klasörlerindeki her bir görüntüyü okuyup 0.25 oranla yeniden \n",
    "boyutlandırınız. Bu görüntülerin her birine öncelikle ikinci maddede geliştirdiğiniz ilgi noktası bulucu algoritmayı uygulayıp ilgi noktalarının konumlarını ve ölçeklerini tespit ediniz. \n",
    "\n",
    "* Ardından ilgi noktalarını merkeze alan ve noktanın ölçeğine bağlı olarak boyutunu ayarlayacağınız W×W büyüklüğündeki bir pencere içerisinde 4×4 hücre ve her bir hücre için 8 uzunluklu histogramlar belirleyerek yönelimli eğimlerin histogramı (HoG) tanımlayıcısını çalıştırınız. \n",
    "\n",
    "* Böylece bir ilgi noktası için 128 uzunluklu bir özellik vektörü oluşturunuz. \n",
    "\n",
    "* HoG tanımlayıcısı OpenCV içerisinden hazır olarak kullanılabilir veya HoG’un interpolasyon aşamaları göz ardı edilerek kodlanabilir. \n",
    "\n",
    "* Bu şekilde tüm görüntüler için oluşturduğunuz ilgi noktalarını ve tanımlayıcılarını her nesne için IP isimli bir klasör altına görüntülerin dosya ismi ile kaydediniz. \n",
    "\n",
    "* İlgi noktalarını belirledikten sonra her nesnenin ilk 8 görüntüsüne ait ilgi noktalarını eğitim son 2 görüntüsüne ait olanları ise test amaçlı kullanarak k en yakın komşu nesne sınıflandırma işlemini gerçekleştiriniz. \n",
    "\n",
    "* K en yakın komşu algoritmasında eğitim olmadığından dosyalar içerisinde yer alan özellikler direkt kullanılacaktır. Toplamda 80 eğitim görüntüsü 20 test görüntüsü veride mevcut olduğuna göre test edilecek her bir görüntü için aşağıdaki adımlar uygulanacaktır: \n",
    "  - Test görüntüsünün her ilgi noktası için eğitim görüntülerinde SSD ile kendisine en yakın olan 2 komşuyu belirle.\n",
    "  - Eşlemedeki belirsizlik yeterince düşük ise ve en yakın komşunun ait olduğu sınıf etiketi hangisiyse test görüntüsü için ilgili sınıfa ait olma sayacını 1 arttır. \n",
    "  - Not: Alternatif olarak K değeri 3, 5 veya 7 gibi belirlenip komşuların çoğunlukla sahip olduğu etikete göre belirli bir sınıfa ait olma sayacı arttırılabilir. \n",
    "  - Tüm ilgi noktaları eşlendikten sonra test görüntüsünün etiketini sayaç değeri en yüksek olan sınıfın etiketi olarak ata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def find_interest_points(image, threshold=0.01):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, 2, 3, threshold)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    return dst\n",
    "\n",
    "def find_interest_points(image, threshold=0.01):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    corners = cv2.goodFeaturesToTrack(gray, 100, threshold, 10, useHarrisDetector=True)\n",
    "    return corners.reshape(-1, 2)\n",
    "\n",
    "def compute_hog(image, interest_points, window_size=128):\n",
    "    keypoints = [cv2.KeyPoint(x=p[0], y=p[1], size=5) for p in interest_points]\n",
    "    \n",
    "    img = cv2.drawKeypoints(image, keypoints, None, color=(0,0,255))\n",
    "    hog = cv2.HOGDescriptor((window_size, window_size), (16, 16), (8, 8), (8, 8), 9)\n",
    "    return hog.compute(img)\n",
    "\n",
    "def knn_classify(X_train, y_train, X_test):\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn.predict(X_test)\n",
    "\n",
    "\n",
    "def process_dataset(dataset_folder, new_folder, window_size=64, resize_factor=0.25):\n",
    "    X = []\n",
    "    y = []\n",
    "    for class_id, class_folder in enumerate(os.listdir(dataset_folder)):\n",
    "        class_folder_path = os.path.join(dataset_folder, class_folder)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for image_file in os.listdir(os.path.join(class_folder_path, 'RAW')):\n",
    "            image_path = os.path.join(class_folder_path, 'RAW', image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image_resized = cv2.resize(image, None, fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "            interest_points = find_interest_points(image_resized)\n",
    "            hog_features = compute_hog(image_resized, interest_points, window_size)\n",
    "            \n",
    "            image_class_folder = os.path.join(new_folder, str(class_folder))\n",
    "            if not os.path.exists(image_class_folder):\n",
    "                os.makedirs(image_class_folder)\n",
    "            np.savetxt(os.path.join(image_class_folder, str(image_file) + \".txt\"), hog_features)\n",
    "\n",
    "            X.append(hog_features)\n",
    "            y.append(class_id)\n",
    "\n",
    "def classify_images(dataset_folder):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_id, class_folder in enumerate(os.listdir(dataset_folder)):\n",
    "        class_folder_path = os.path.join(dataset_folder, class_folder)\n",
    "        if not os.path.isdir(class_folder_path):\n",
    "            continue\n",
    "        for feat_file in os.listdir(os.path.join(class_folder_path, 'RAW')):\n",
    "            image_class_folder = os.path.join(dataset_folder, str(class_folder))\n",
    "\n",
    "\n",
    "            hog_features = np.loadtxt(os.path.join(image_class_folder, str(feat_file) + \".txt\"))\n",
    "            \n",
    "            X.append(hog_features)\n",
    "            y.append(class_id)\n",
    "\n",
    "\n",
    "    X, y = shuffle(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "        \n",
    "    y_pred = knn_classify(X_train, y_train, X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m new_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset_processed\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m process_dataset(dataset_folder, new_folder, window_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, resize_factor\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m classify_images(new_folder)\n",
      "Cell \u001b[1;32mIn[2], line 52\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(dataset_folder, new_folder, window_size, resize_factor)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(image_class_folder):\n\u001b[0;32m     51\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(image_class_folder)\n\u001b[1;32m---> 52\u001b[0m np\u001b[39m.\u001b[39;49msavetxt(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(image_class_folder, \u001b[39mstr\u001b[39;49m(image_file) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m), hog_features)\n\u001b[0;32m     54\u001b[0m X\u001b[39m.\u001b[39mappend(hog_features)\n\u001b[0;32m     55\u001b[0m y\u001b[39m.\u001b[39mappend(class_id)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32me:\\Yüksek Lisans\\MSc_Projects\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:1605\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1602\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMismatch between array dtype (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m) and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1603\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39mformat specifier (\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1604\u001b[0m                             \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(X\u001b[39m.\u001b[39mdtype), \u001b[39mformat\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m         fh\u001b[39m.\u001b[39;49mwrite(v)\n\u001b[0;32m   1607\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(footer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1608\u001b[0m     footer \u001b[39m=\u001b[39m footer\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m comments)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_folder = 'dataset'\n",
    "new_folder = 'dataset_processed'\n",
    "process_dataset(dataset_folder, new_folder, window_size=64, resize_factor=0.25)\n",
    "classify_images(new_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f16f5f404429e101810fef1613a59eafcd24ead4f7b4dfe806cd2f60b94a1715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
